{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971e0bed-b911-4643-8d7d-0bc136550c44",
   "metadata": {},
   "source": [
    "# Exploring multiple approaches to machine learning across multiple small EHD experimental datasets\n",
    " - The task is to predict (regress) the size of printed features, as a function of waveform inputs to the EHD printer\n",
    " - A second task is to predict (classify) whether a given waveform input will produce any printed pattern at all. (This is equivalent to understanding the print onset voltage threshold.)\n",
    " - Multiple hidden confounding variables are likely, such as ink/tip/substrate/atmospheric condition; ink and tip clogging; print tip height from the substrate. Some of these will be relatively constant for each run of experiments, some will vary from feature to feature.\n",
    " - Ink dynamics at the printing tip are complex and nonlinear, with electrical and fluid/acoustic phenomena that interact with each other.\n",
    "\n",
    "## Goals\n",
    " - In regression, aim for <3% mean absolute error (from the predicted outcome)\n",
    " - In classification, aim for >0.9 ROC AUC\n",
    " - For a new/test set, achieve these in <=100 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30913236-8a5d-4983-b31b-9ae56f38dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sys.path.append('..')\n",
    "from ehd_dataset import EHD_Loader\n",
    "from ehd_models import EHD_Model\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c326ac0-8e77-4024-8fde-d3bfe5aaa08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load 10-Mar-2022 large nozzle mosaic: 'DataFrame' object has no attribute 'note'\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\29-Mar-2022 lg 1cm 300 points\toffset 0\tcorr 0.4960008364961841\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\2-May-2022__run 1\toffset 7\tcorr 0.20797462285908108\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\2-May-2022__run 2\toffset 4\tcorr 0.5656140913387249\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\23-May-2022_squares\toffset 8\tcorr 0.5137128998522692\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\24-May-2022 large harmonics\toffset 0\tcorr 0.5869081626562916\n",
      "Datasets Loaded!\n",
      ">> Quick correlation validation check -- [auac; vec L2] <<\n",
      "<<29-Mar-2022 lg 1cm 300 points -- [0.496; 0.650]>> <<2-May-2022__run 1 -- [0.208; 0.239]>> <<2-May-2022__run 2 -- [0.566; 0.748]>> <<23-May-2022_squares -- [0.514; 0.630]>> <<24-May-2022 large harmonics -- [0.587; 0.764]>> "
     ]
    }
   ],
   "source": [
    "INDEX = \"C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\dataset_index.xlsx\"\n",
    "loader = EHD_Loader(INDEX)\n",
    "print(\"Datasets Loaded!\\n>> Quick correlation validation check -- [auac; vec L2] <<\")\n",
    "\n",
    "for i, df in enumerate(loader.datasets):\n",
    "    # print(loader.names[i])\n",
    "    AUAC, _ = pearsonr(df.area,\n",
    "                       df.wave.apply(lambda x: np.sum(np.abs(x))))\n",
    "    # print(f\"AUAC correlation: {corr}\")\n",
    "    # Area has >0.7 corr vs L2-norm of the wavevector\n",
    "    VL2, _ = pearsonr(df.area,\n",
    "                       df.vector.apply(lambda x: np.sqrt(np.sum(x**2))))\n",
    "    print(f\"<<{loader.names[i]} -- [{AUAC:.3f}; {VL2:.3f}]\", end='>> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5afbe9d-9041-40c6-9389-633bf5cb5eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ehd_models import EHD_Model\n",
    "\n",
    "#reg_results = pd.DataFrame(columns=('architecture', 'fold', 'train_size', 'MAE', 'PAE'))\n",
    "reg_results = []\n",
    "for architecture in ['MLE']:  # Print Area Regression Models <<<<<<<<<<<<<<<<<<<<\n",
    "    break\n",
    "    model = EHD_Model(architecture=architecture)\n",
    "\n",
    "    for fold in range(loader.num_folds):\n",
    "        pretrain_set, eval_set, eval_name = loader.folded_dataset(fold=fold, xtype='wave', ytype='area',\n",
    "                                                                 # filters=[('vector', lambda x: len(x), 6)])\n",
    "                                                                 filters=[])\n",
    "        model.pretrain(pretrain_set)\n",
    "        output = model.evaluate(eval_set)\n",
    "\n",
    "        output['architecture'] = architecture\n",
    "        output['eval_dataset'] = eval_name\n",
    "        reg_results.append(output)\n",
    "#reg_results = pd.DataFrame.from_dict(reg_results)\n",
    "\n",
    "\n",
    "#class_results = pd.DataFrame(columns=('architecture', 'fold', 'train_size', 'AUC'))\n",
    "class_results = []\n",
    "for architecture in ['MLE_class']:  # Jetting Classification Models <<<<<<<<<<<<<<<<<<<<\n",
    "    model = EHD_Model(architecture=architecture)\n",
    "\n",
    "    for fold in range(loader.num_folds):\n",
    "        pretrain_set, eval_set, eval_name = loader.folded_dataset(fold=fold, xtype='wave', ytype='jetted',\n",
    "                                                       # filters=[('vector', lambda x: len(x), 6)])\n",
    "                                                       filters=[])\n",
    "        model.pretrain(pretrain_set)\n",
    "        output = model.evaluate(eval_set)\n",
    "\n",
    "        output['architecture'] = architecture\n",
    "        output['eval_dataset'] = eval_name\n",
    "        class_results.append(output)\n",
    "\n",
    "# TODO visualize results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
