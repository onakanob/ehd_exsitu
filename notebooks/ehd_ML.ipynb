{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971e0bed-b911-4643-8d7d-0bc136550c44",
   "metadata": {},
   "source": [
    "# Exploring multiple approaches to machine learning across multiple small EHD experimental datasets\n",
    " - The task is to predict (regress) the size of printed features, as a function of waveform inputs to the EHD printer\n",
    " - A second task is to predict (classify) whether a given waveform input will produce any printed pattern at all. (This is equivalent to understanding the print onset voltage threshold.)\n",
    " - Multiple hidden confounding variables are likely, such as ink/tip/substrate/atmospheric condition; ink and tip clogging; print tip height from the substrate. Some of these will be relatively constant for each run of experiments, some will vary from feature to feature.\n",
    " - Ink dynamics at the printing tip are complex and nonlinear, with electrical and fluid/acoustic phenomena that interact with each other.\n",
    "\n",
    "## Goals\n",
    " - In regression, aim for <3% mean absolute error (from the predicted outcome)\n",
    " - In classification, aim for >0.9 ROC AUC\n",
    " - For a new/test set, achieve these in <=100 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30913236-8a5d-4983-b31b-9ae56f38dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sys.path.append('..')\n",
    "from ehd_dataset import EHD_Loader\n",
    "from ehd_models import EHD_Model\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c326ac0-8e77-4024-8fde-d3bfe5aaa08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load 10-Mar-2022 large nozzle mosaic: 'DataFrame' object has no attribute 'note'\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\29-Mar-2022 lg 1cm 300 points\toffset 0\tcorr 0.4960008364961841\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\2-May-2022__run 1\toffset 7\tcorr 0.20797462285908108\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\2-May-2022__run 2\toffset 4\tcorr 0.5656140913387249\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\23-May-2022_squares\toffset 8\tcorr 0.5137128998522692\n",
      "dataset C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\24-May-2022 large harmonics\toffset 0\tcorr 0.5869081626562916\n",
      "Datasets Loaded!\n",
      ">> Quick correlation validation check -- [auac; vec L2] <<\n",
      "<<29-Mar-2022 lg 1cm 300 points -- [0.496; 0.650]>> <<2-May-2022__run 1 -- [0.208; 0.239]>> <<2-May-2022__run 2 -- [0.566; 0.748]>> <<23-May-2022_squares -- [0.514; 0.630]>> <<24-May-2022 large harmonics -- [0.587; 0.764]>> "
     ]
    }
   ],
   "source": [
    "INDEX = \"C:\\Dropbox\\SPEED\\Self Driving EHD\\Datasets\\dataset_index.xlsx\"\n",
    "loader = EHD_Loader(INDEX)\n",
    "print(\"Datasets Loaded!\\n>> Quick correlation validation check -- [auac; vec L2] <<\")\n",
    "\n",
    "for i, df in enumerate(loader.datasets):\n",
    "    AUAC, _ = pearsonr(df.area,\n",
    "                       df.wave.apply(lambda x: np.sum(np.abs(x))))\n",
    "    VL2, _ = pearsonr(df.area,\n",
    "                       df.vector.apply(lambda x: np.sqrt(np.sum(x**2))))\n",
    "    print(f\"<<{loader.names[i]} -- [{AUAC:.3f}; {VL2:.3f}]\", end='>> ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5afbe9d-9041-40c6-9389-633bf5cb5eb2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating regression model type: MLE\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating regression model type: cold_RF\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating regression model type: cold_MLP\n",
      "fold 0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda3\\envs\\ehd\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating classification model type: MLE_class\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating classification model type: cold_RF_class\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating classification model type: cold_MLP_class\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m architecture, params \u001b[38;5;129;01min\u001b[39;00m model_architectures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating classification model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mEHD_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset_fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(loader\u001b[38;5;241m.\u001b[39mnum_folds(model\u001b[38;5;241m.\u001b[39mfilters)):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_fold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Dropbox\\Python\\ehd_exsitu\\notebooks\\..\\ehd_models\\Model.py:40\u001b[0m, in \u001b[0;36mEHD_Model.__init__\u001b[1;34m(self, architecture, params)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, architecture, params\u001b[38;5;241m=\u001b[39m{}):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchitecture \u001b[38;5;241m=\u001b[39m architecture\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmake_model_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchitecture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpretrainer\n",
      "File \u001b[1;32mC:\\Dropbox\\Python\\ehd_exsitu\\notebooks\\..\\ehd_models\\Model.py:30\u001b[0m, in \u001b[0;36mmake_model_like\u001b[1;34m(architecture, params)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RF_Classifier(params)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m architecture \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcold_MLP_class\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMLP_Classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot a valid model architecture: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Dropbox\\Python\\ehd_exsitu\\notebooks\\..\\ehd_models\\cold_models.py:130\u001b[0m, in \u001b[0;36mMLP_Classifier.__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# TODO introduce hyperparams\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m    129\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhiten\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[1;32m--> 130\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m, MLPClassifier(max_iter\u001b[38;5;241m=\u001b[39m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_iter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[0;32m    131\u001b[0m ])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'max_iter'"
     ]
    }
   ],
   "source": [
    "from ehd_models import EHD_Model\n",
    "\n",
    "\n",
    "# Print Area Regression Models <<<<<<<<<<<<<<<<<<<<\n",
    "model_architectures = {'MLE': {},\n",
    "                       'cold_RF': {},\n",
    "                       'cold_MLP': {'max_iter': 100_000}}\n",
    "reg_results = []\n",
    "for architecture, params in model_architectures.items():\n",
    "    print(f'\\nEvaluating regression model type: {architecture}')\n",
    "    model = EHD_Model(architecture=architecture, params=params)\n",
    "    \n",
    "    # for dataset_fold in range(loader.num_folds()):\n",
    "    for dataset_fold in range(loader.num_folds(model.filters)):  # TODO loader be smart about folds based on filters\n",
    "        print(f\"fold {dataset_fold}\", end=\" \")\n",
    "        pretrain_set, eval_set, eval_name = loader.folded_dataset(fold=dataset_fold, xtype=model.xtype, ytype=model.ytype,\n",
    "                                                                 pretrain=model.pretrainer, filters=model.filters)\n",
    "        # try:\n",
    "        if model.pretrainer:\n",
    "            model.pretrain(pretrain_set)\n",
    "        output = model.evaluate(eval_set)\n",
    "\n",
    "        output['architecture'] = architecture\n",
    "        output['eval_dataset'] = eval_name\n",
    "        reg_results.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a97aae51-86f4-4243-9e8f-e7536c103933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating classification model type: MLE_class\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating classification model type: cold_RF_class\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 \n",
      "Evaluating classification model type: cold_MLP_class\n",
      "fold 0 fold 1 fold 2 fold 3 fold 4 "
     ]
    }
   ],
   "source": [
    "# Jetting Classification Models <<<<<<<<<<<<<<<<<<<<\n",
    "model_architectures = {'MLE_class': {},\n",
    "                       'cold_RF_class': {},\n",
    "                       'cold_MLP_class': {'max_iter': 100_000}}\n",
    "class_results = []\n",
    "for architecture, params in model_architectures.items():\n",
    "    print(f'\\nEvaluating classification model type: {architecture}')\n",
    "    model = EHD_Model(architecture=architecture, params=params)\n",
    "\n",
    "    for dataset_fold in range(loader.num_folds(model.filters)):\n",
    "        print(f\"fold {dataset_fold}\", end=\" \")\n",
    "        pretrain_set, eval_set, eval_name = loader.folded_dataset(fold=dataset_fold, xtype=model.xtype, ytype=model.ytype,\n",
    "                                                                 pretrain=model.pretrainer, filters=model.filters)\n",
    "        model.pretrain(pretrain_set)\n",
    "        output = model.evaluate(eval_set)\n",
    "\n",
    "        output['architecture'] = architecture\n",
    "        output['eval_dataset'] = eval_name\n",
    "        class_results.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4321b309-62d2-4949-80b3-e819ea6e1188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "OUT_XLSX = 'eval_summary.xlsx'\n",
    "xlsx_writer = pd.ExcelWriter(OUT_XLSX)\n",
    "\n",
    "def n_walk_result_vis(df, x, y, trends, outfile=None):\n",
    "    bar_ci = 0.95  # 'sd' for standard deviation\n",
    "    sns.lineplot(\n",
    "        data=df.loc[~df['singleton']],\n",
    "        x=x, y=y, hue=trends, style=trends,\n",
    "        markers=True,\n",
    "        err_style=\"bars\", ci=bar_ci,\n",
    "        linewidth=0.3\n",
    "    )\n",
    "    ticks = df[x].loc[~df['singleton']].unique()\n",
    "    plt.xticks(ticks=ticks,\n",
    "               labels=np.round(10**ticks).astype(int))\n",
    "    plt.xlabel('dataset size')\n",
    "    if y == 'MSE':\n",
    "        plt.ylim(0, 6e9)\n",
    "    if y == 'MAE':\n",
    "        plt.ylim(0, 100_000)\n",
    "    if y == 'MAPE':\n",
    "        plt.ylim(0, 100)\n",
    "    if outfile is None:\n",
    "        plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.rcParams['figure.figsize'] = (7.0, 5.0) # set default size of plots\n",
    "        plt.savefig(outfile, bbox_inches='tight', pad_inches=0.1, transparent=False, dpi=500)\n",
    "        plt.clf()\n",
    "\n",
    "# Expand, log, and vis regression results\n",
    "df = pd.concat(reg_results, ignore_index=True)\n",
    "df['log_size'] = df['train_size'].apply(lambda x: np.log10(x).round(3))\n",
    "df['MAPE'] = df['MAPE'].apply(lambda x: 100 * x)\n",
    "df['singleton'] = df['train_size'].apply(lambda x: (df['train_size'] == x).sum() <= len(df['architecture'].unique()))\n",
    "\n",
    "for metric in ['MAE', 'MAPE', 'MSE', 'r']:  # MSLE left out for now\n",
    "    n_walk_result_vis(df, x='log_size', y=metric, trends='architecture', outfile=f\"{metric}.png\")\n",
    "    \n",
    "df.to_excel(xlsx_writer, index=False, sheet_name='Regression')\n",
    "\n",
    "# Expand, log, and vis classification results\n",
    "df = pd.concat(class_results, ignore_index=True)\n",
    "df['log_size'] = df['train_size'].apply(lambda x: np.log10(x).round(3))\n",
    "df['singleton'] = df['train_size'].apply(lambda x: (df['train_size'] == x).sum() <= len(df['architecture'].unique()))\n",
    "    \n",
    "df.to_excel(xlsx_writer, index=False, sheet_name='Classification')\n",
    "\n",
    "for metric in ['F1', 'AUC']:\n",
    "    n_walk_result_vis(df, x='log_size', y=metric, trends='architecture', outfile=f\"{metric}.png\")\n",
    "\n",
    "xlsx_writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
