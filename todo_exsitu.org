* Experiment
** TODO modify tuner for regression - tune a regression model
** TODO write ensemble loader (one class, one regress)
** TODO write point spread generator - take range of values from the datasets
** TODO finish script to generate recipes
* codebase
** DONE add testing for all model training and eval functions
CLOSED: [2023-01-15 Sun 14:41]
Not technically complete, but a cross section is there and the test function works well.
** DONE Make image preprocessing steps selectable (patch_tools:43, patches_gui:164)
CLOSED: [2023-01-05 Thu 11:47]
** DONE Switch these data filters to _experiment_ level inputs: xtype, ytype, filters
CLOSED: [2023-01-05 Thu 11:48]
** DONE finish modifying run script for all-in-one entry point. 
CLOSED: [2022-12-26 Mon 22:09]
*** DONE run through it with one dataset, just to be sure.
CLOSED: [2022-12-26 Mon 22:09]
*** DONE Add cold-start binary switch to the run script.
CLOSED: [2022-12-24 Sat 15:52]
** DONE per-image threshold and min_size settings using CSV (populate w/ default values)
CLOSED: [2022-12-16 Fri 21:40]
** DONE pipe "declog" to the actual json file
CLOSED: [2022-12-24 Sat 16:40]

* dataset
** TODO Visualizer for per-point regression in datasets, to spot experimental de-sync
** TODO Try last X/last Y/delta-X (instead of new-X) to make it easier for the random forest -KJ
** DONE Square waves abs voltage in dataset
CLOSED: [2023-01-10 Tue 12:09]
** DONE Change ehd_dir2data so that pulsewidth doesn't get multiplied by voltage gain
CLOSED: [2023-01-10 Tue 12:10]
** DONE Normalize just the voltage (not the pulsewidth)
CLOSED: [2023-01-10 Tue 15:12]
** DONE Regress only when jetting
CLOSED: [2023-01-09 Mon 12:52]
** DONE for small train sizes, multiple samples from random indices in the run
CLOSED: [2022-08-09 Tue 23:02]
** DONE double check area units and high MAE values
CLOSED: [2022-08-09 Tue 15:53]
** DONE t-1 return type that includes y-spec
CLOSED: [2022-07-26 Tue 17:23]
** NOTDONE Add synthetic dataset to validate model behaviors (any Markov process + noise) -KJ

* models
** TODO Try cold-start linear last-X/Y (and linear models in general) -KJ
** DONE Added "normed_rf" model type - just another Allpre random forest, but new label for the normed_squares datatype
** convolutional input layer transfer?
** latent space inputs and runtime L-estimator
** supervise updating L
** recurrent L estimator
** DONE bootstrap model ensemble and runtime selector
CLOSED: [2022-07-26 Tue 17:24]


* analysis
** TODO Switch nomenclature to "tasks" and "target task" -KJ
** Switch from raw values to +/- dataset mean
Larger data numbers could look better if the larger datasets happen to be easier to predict. Instead we could look at average deviation from the mean for each dataset? Just a thought.
