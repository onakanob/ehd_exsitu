* codebase
** TODO Make image preprocessing steps selectable (patch_tools:43, patches_gui:164)
** TODO Switch these data filters to _experiment_ level inputs: xtype, ytype, filters
** TODO add testing for all model training and eval functions

** DONE finish modifying run script for all-in-one entry point. 
CLOSED: [2022-12-26 Mon 22:09]
*** DONE run through it with one dataset, just to be sure.
CLOSED: [2022-12-26 Mon 22:09]
*** DONE Add cold-start binary switch to the run script.
CLOSED: [2022-12-24 Sat 15:52]
** DONE per-image threshold and min_size settings using CSV (populate w/ default values)
CLOSED: [2022-12-16 Fri 21:40]
** DONE pipe "declog" to the actual json file
CLOSED: [2022-12-24 Sat 16:40]

* dataset
** TODO Try last X/last Y/delta-X (instead of new-X) to make it easier for the random forest -KJ
** TODO Add synthetic dataset to validate model behaviors (any Markov process + noise) -KJ
** DONE for small train sizes, multiple samples from random indices in the run
CLOSED: [2022-08-09 Tue 23:02]
** DONE double check area units and high MAE values
CLOSED: [2022-08-09 Tue 15:53]
** DONE t-1 return type that includes y-spec
CLOSED: [2022-07-26 Tue 17:23]


* models
** TODO Add another baseline - always predict last Y -KJ
** TODO Try cold-start linear last-X/Y (and linear models in general) -KJ
** convolutional input layer transfer?
** latent space inputs and runtime L-estimator
** supervise updating L
** recurrent L estimator
** DONE bootstrap model ensemble and runtime selector
CLOSED: [2022-07-26 Tue 17:24]


* analysis
** TODO Switch nomenclature to "tasks" and "target task" -KJ
** Switch from raw values to +/- dataset mean
Larger data numbers could look better if the larger datasets happen to be easier to predict. Instead we could look at average deviation from the mean for each dataset? Just a thought.
